{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv3 Train Sageband.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeqinghuang516/UCSD-ECE285-Object-Detection-Using-Deep-Learning/blob/master/YOLO/YOLOv3_Train_Sageband.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10sl9S8OcyMC",
        "colab_type": "text"
      },
      "source": [
        "## Git clone the repository and install the requirments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKpNQ-lTbpN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/yeqinghuang516/UCSD-ECE285-Object-Detection-Using-Deep-Learning.git\n",
        "% cd UCSD-ECE285-Object-Detection-Using-Deep-Learning/YOLO\n",
        "! sudo pip3 install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5i2Ha4cD5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "sys.path.append('/content/UCSD-ECE285-Object-Detection-Using-Deep-Learning/YOLO/')\n",
        "\n",
        "\n",
        "from models import *\n",
        "from utils.utils import *\n",
        "from utils.logger import *\n",
        "from utils.datasets import *\n",
        "from mytest import evaluate\n",
        "\n",
        "from terminaltables import AsciiTable\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6bKF6vHfCWe",
        "colab_type": "text"
      },
      "source": [
        "## Setting up parameters for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBO9GqLcxaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200 # number of epochs\n",
        "batch_size = 32 #size of each image batch\n",
        "gradient_accumulations = 2 #number of gradient accums before step\n",
        "model_def = 'config/yolov3.cfg' #path to model definition file\n",
        "n_cpu = 8 #number of cpu threads to use during batch generation\n",
        "img_size = 224#size of each image dimension\n",
        "checkpoint_interval = 1 # interval between saving model weights\n",
        "evaluation_interval = 2 # interval evaluations on validation set\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger = Logger(\"logs\")\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "metrics = ['grid_size', 'loss', 'x', 'y', 'w', 'h', 'conf', 'cls', 'cls_acc', 'recall50', 'recall75', 'precision', 'conf_obj', 'conf_noobj']\n",
        "class_names = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_B6wRufIHc",
        "colab_type": "text"
      },
      "source": [
        "## Download and Initialize datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTXOCpYucxca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('data', exist_ok = True)\n",
        "root = 'data'\n",
        "VOCdataset = VOCDataset(root, image_set = 'train', train = True)\n",
        "VOCtestset = VOCDataset(root, image_set = 'val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7foox8HXf-rN",
        "colab_type": "text"
      },
      "source": [
        "## Define pretrained weights (if training from previous checkpoints or pretrained weights)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NM6ecejgEuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_weights = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B6brlIDgo6t",
        "colab_type": "text"
      },
      "source": [
        "## Initiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr6X7SSqcxei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dfaae88-4a50-4ac9-ba0b-decfced066ba"
      },
      "source": [
        "model = Darknet(model_def, loss_mode = \"modified\").to(device)\n",
        "model.apply(weights_init_normal);\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "cur_epoch = 0\n",
        "\n",
        "# If specified we start from checkpoint, load checkpoint\n",
        "if pretrained_weights:\n",
        "    if pretrained_weights.endswith(\".pth\"):\n",
        "        checkpoint = torch.load(pretrained_weights)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        cur_epoch = checkpoint['epoch'] + 1\n",
        "        print('load state dict')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The loss mode is modified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhOdEJuAgwWW",
        "colab_type": "text"
      },
      "source": [
        "## Initiate Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6qBQO0tcxi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset = VOCdataset,\n",
        "    batch_size= batch_size,\n",
        "    num_workers= n_cpu,\n",
        "    shuffle = True,\n",
        "    pin_memory= True,\n",
        "    drop_last = False,\n",
        "    collate_fn= VOCdataset.collate_fn,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K01wV5QqhRnt",
        "colab_type": "text"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVFPY2uJcxlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(cur_epoch, epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for batch_i, (imgs, targets) in enumerate(dataloader):\n",
        "      batches_done = len(dataloader) * epoch + batch_i\n",
        "      imgs = Variable(imgs.to(device))\n",
        "      targets = Variable(targets.to(device), requires_grad=False)\n",
        "\n",
        "      loss, outputs = model(imgs, targets)\n",
        "      loss.backward()\n",
        "\n",
        "      if batches_done % gradient_accumulations:\n",
        "          # Accumulates gradient before each step\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "    \n",
        "      # ----------------\n",
        "      #   Log progress\n",
        "      # ----------------\n",
        "\n",
        "      log_str = \"\\n---- [Epoch %d/%d, Batch %d/%d] ----\\n\" % (epoch, epochs, batch_i, len(dataloader))\n",
        "\n",
        "      metric_table = [[\"Metrics\", *[f\"YOLO Layer {i}\" for i in range(len(model.yolo_layers))]]]\n",
        "\n",
        "      # Log metrics at each YOLO layer\n",
        "      for i, metric in enumerate(metrics):\n",
        "          formats = {m: \"%.6f\" for m in metrics}\n",
        "          formats[\"grid_size\"] = \"%2d\"\n",
        "          formats[\"cls_acc\"] = \"%.2f%%\"\n",
        "          row_metrics = [formats[metric] % yolo.metrics.get(metric, 0) for yolo in model.yolo_layers]\n",
        "          metric_table += [[metric, *row_metrics]]\n",
        "\n",
        "          # Tensorboard logging\n",
        "          tensorboard_log = []\n",
        "          for j, yolo in enumerate(model.yolo_layers):\n",
        "              for name, metric in yolo.metrics.items():\n",
        "                  if name != \"grid_size\":\n",
        "                      tensorboard_log += [(f\"{name}_{j+1}\", metric)]\n",
        "          tensorboard_log += [(\"loss\", loss.item())]\n",
        "          logger.list_of_scalars_summary(tensorboard_log, batches_done)\n",
        "\n",
        "      log_str += AsciiTable(metric_table).table\n",
        "      log_str += f\"\\nTotal loss {loss.item()}\"\n",
        "\n",
        "      # Determine approximate time left for epoch\n",
        "      epoch_batches_left = len(dataloader) - (batch_i + 1)\n",
        "      time_left = datetime.timedelta(seconds=epoch_batches_left * (time.time() - start_time) / (batch_i + 1))\n",
        "      log_str += f\"\\n---- ETA {time_left}\"\n",
        "      \n",
        "      # print training log\n",
        "      print(log_str)\n",
        "\n",
        "      model.seen += imgs.size(0)\n",
        "    \n",
        "    if epoch % evaluation_interval == 0:\n",
        "        print(\"\\n---- Evaluating Model ----\")\n",
        "        # Evaluate the model on the validation set\n",
        "        precision, recall, AP, f1, ap_class = evaluate(\n",
        "            model,\n",
        "            dataset = VOCtestset,\n",
        "            iou_thres=0.5,\n",
        "            conf_thres=0.5,\n",
        "            nms_thres=0.5,\n",
        "            img_size=img_size,\n",
        "            batch_size=8,\n",
        "        )\n",
        "        evaluation_metrics = [\n",
        "            (\"val_precision\", precision.mean()),\n",
        "            (\"val_recall\", recall.mean()),\n",
        "            (\"val_mAP\", AP.mean()),\n",
        "            (\"val_f1\", f1.mean()),\n",
        "        ]\n",
        "        logger.list_of_scalars_summary(evaluation_metrics, epoch)\n",
        "\n",
        "        # Print class APs and mAP\n",
        "        ap_table = [[\"Index\", \"Class name\", \"AP\"]]\n",
        "        for i, c in enumerate(ap_class):\n",
        "            ap_table += [[c, class_names[c], \"%.5f\" % AP[i]]]\n",
        "        print(AsciiTable(ap_table).table)\n",
        "        print(f\"---- mAP {AP.mean()}\")\n",
        "    \n",
        "    # save checkpoints\n",
        "    if epoch % checkpoint_interval == 0:\n",
        "        state_dict = {'net': model.state_dict(), 'optimizer': optimizer.state_dict(),'epoch': epoch}\n",
        "        torch.save(state_dict, f\"checkpoints/yolov3_ckpt_%d.pth\" % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHb0GvYgcxni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWHYIyCWcxpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsBgoQU-cxsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIkl6eRhcxue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbNisAo1cxxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMm6YoxXcxzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfYuygnmcx1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}